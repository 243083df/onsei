{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454ed7e9-98ee-438f-a512-35d72b3ba660",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets;\n",
    "from onsei.utils import SpeechRecord;\n",
    "import numpy as np;\n",
    "from bqplot import pyplot as plt;\n",
    "from bqplot import DateScale, LinearScale, Lines, Axis, Figure;\n",
    "from ipywebrtc import AudioRecorder, CameraStream, AudioStream;\n",
    "\n",
    "# Globals\n",
    "\n",
    "samples = {\n",
    "    \"僕の知人の経営者に\": {\n",
    "        \"filename\": \"data/ps/ps1_boku_no_chijin-teacher2.wav\",\n",
    "        \"transcript\": \"ぼく の ちじん の けいえい しゃに\",\n",
    "    },\n",
    "    \"水をマレーシアから買わなくてはならないのです\": {\n",
    "        \"filename\": \"data/jsut_basic5000_sample/BASIC5000_0001.wav\",\n",
    "        \"transcript\": \"みず を まれーしあ から かわなくて は ならない の です\",\n",
    "    }\n",
    "};\n",
    "\n",
    "default_sample_key = list(samples.keys())[0]\n",
    "default_sample = samples[default_sample_key]\n",
    "\n",
    "teacher_rec = None\n",
    "student_rec = None\n",
    "\n",
    "# Create widgets\n",
    "\n",
    "w_select = widgets.Dropdown(\n",
    "    options=samples.keys(),\n",
    "    value=default_sample_key,\n",
    "    description='Samples:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "w_load_btn = widgets.Button(description=\"Load\")\n",
    "\n",
    "w_audio = widgets.Audio(value=b'', format='wav', autoplay=True, loop=False)\n",
    "\n",
    "w_sentence = widgets.HTML(value='')\n",
    "\n",
    "camera = CameraStream(constraints={'audio': True, 'video': False})\n",
    "w_recorder = AudioRecorder(stream=camera)\n",
    "\n",
    "w_compare_btn = widgets.Button(description=\"Compare\")\n",
    "\n",
    "\n",
    "scale_ts = LinearScale()\n",
    "scale_cmp_ts = LinearScale()\n",
    "scale_pitch = LinearScale()\n",
    "scale_intensity = LinearScale()\n",
    "scale_norm_pitch = LinearScale()\n",
    "\n",
    "line_pitch = Lines(x=[], y=[], scales={'x': scale_ts, 'y': scale_pitch}, labels=[\"Pitch\"], colors=[\"dodgerblue\"], display_legend=True)\n",
    "line_intensity = Lines(x=[], y=[], scales={'x': scale_ts, 'y': scale_intensity}, labels=[\"Intensity\"], colors=[\"lightgreen\"], fill=\"bottom\", display_legend=True)\n",
    "line_vad_intensity = Lines(x=[], y=[], scales={'x': scale_ts, 'y': scale_intensity}, labels=[\"Detected Speech\"], colors=[\"red\"], fill=\"bottom\", display_legend=True)\n",
    "ax_ts = Axis(scale=scale_ts, label=\"Time (s)\", grid_lines=\"solid\")\n",
    "ax_pitch = Axis(scale=scale_intensity, label=\"Pitch (Hz)\", orientation=\"vertical\", grid_lines=\"solid\", side=\"left\")\n",
    "ax_intensity = Axis(scale=scale_intensity, label=\"Intensity (dB)\", orientation=\"vertical\", grid_lines=\"solid\", side=\"right\")\n",
    "fig_teacher = Figure(marks=[line_intensity, line_vad_intensity, line_pitch], axes=[ax_ts, ax_pitch, ax_intensity], legend_location=\"top-right\", title=\"Teacher's recording\")\n",
    "\n",
    "line_cmp_pitch_teacher = Lines(x=[], y=[], scales={'x': scale_ts, 'y': scale_norm_pitch}, labels=[\"Teacher Norm Pitch\"], colors=[\"blue\"], display_legend=True)\n",
    "line_cmp_pitch_student = Lines(x=[], y=[], scales={'x': scale_ts, 'y': scale_norm_pitch}, labels=[\"Student Norm Pitch\"], colors=[\"red\"], display_legend=True)\n",
    "ax_cmp_ts = Axis(scale=scale_cmp_ts, label=\"Time (s)\", grid_lines=\"solid\")\n",
    "ax_cmp_pitch = Axis(scale=scale_norm_pitch, label=\"Normalized Pitch\", orientation=\"vertical\", grid_lines=\"solid\", side=\"left\")\n",
    "fig_cmp = Figure(marks=[line_cmp_pitch_teacher, line_cmp_pitch_student], axes=[ax_cmp_ts, ax_cmp_pitch], legend_location=\"top-right\", title=\"Pitch comparison\")\n",
    "\n",
    "# Callbacks\n",
    "\n",
    "def clear_compare_plot():\n",
    "    with line_cmp_pitch_student.hold_sync(), line_cmp_pitch_teacher.hold_sync():\n",
    "        line_cmp_pitch_student.x = []\n",
    "        line_cmp_pitch_student.y = []\n",
    "        line_cmp_pitch_teacher.x = []\n",
    "        line_cmp_pitch_teacher.y = []\n",
    "\n",
    "def update_compare_plot():\n",
    "    with line_cmp_pitch_student.hold_sync(), line_cmp_pitch_teacher.hold_sync():\n",
    "        line_cmp_pitch_student.x = teacher_rec.align_ts\n",
    "        line_cmp_pitch_student.y = student_rec.norm_aligned_pitch\n",
    "        line_cmp_pitch_teacher.x = teacher_rec.align_ts\n",
    "        line_cmp_pitch_teacher.y = teacher_rec.norm_aligned_pitch\n",
    "\n",
    "def get_sample_audio_data(sample):\n",
    "    return open(sample['filename'], 'rb').read()\n",
    "\n",
    "def update_teacher_plot():\n",
    "    global teacher\n",
    "\n",
    "    with line_pitch.hold_sync(), line_intensity.hold_sync(), line_vad_intensity.hold_sync():\n",
    "        y = teacher_rec.pitch_freq_filtered.copy()\n",
    "        y[y == 0] = np.nan\n",
    "        line_pitch.x = teacher_rec.pitch.xs()\n",
    "        line_pitch.y = y\n",
    "\n",
    "        line_intensity.x = teacher_rec.intensity.xs()\n",
    "        line_intensity.y = teacher_rec.intensity.values.T\n",
    "\n",
    "        line_vad_intensity.x = teacher_rec.intensity.xs()[teacher_rec.begin_idx:teacher_rec.end_idx]\n",
    "        line_vad_intensity.y = teacher_rec.intensity.values.T[teacher_rec.begin_idx:teacher_rec.end_idx]\n",
    "\n",
    "def update_sample(sample):\n",
    "    global teacher_rec\n",
    "\n",
    "    with w_sentence.hold_sync():\n",
    "        w_sentence.value = sample['transcript']\n",
    "\n",
    "    teacher_rec = SpeechRecord(sample['filename'], transcript=sample['transcript'], name=\"Teacher\");\n",
    "\n",
    "    w_audio.value = get_sample_audio_data(sample)\n",
    "    \n",
    "    update_teacher_plot()\n",
    "\n",
    "update_sample(default_sample);\n",
    "\n",
    "def load_selected_sample(_):\n",
    "    sample = samples[w_select.value]\n",
    "    update_sample(sample)\n",
    "    clear_compare_plot()\n",
    "\n",
    "w_load_btn.on_click(load_selected_sample);\n",
    "        \n",
    "\n",
    "def run_compare(_):\n",
    "    global student_rec\n",
    "\n",
    "    sample = samples[w_select.value]\n",
    "\n",
    "    #w_recorder.save('test.webm')\n",
    "    #!ffmpeg -hide_banner -loglevel error -y -i test.webm -ar 16000 -ac 1 test.wav\n",
    "    #student_wav_filename = 'test.wav'\n",
    "    # Alternatively, here is a sample:\n",
    "    student_wav_filename = \"data/ps/ps1_boku_no_chijin-student3.wav\"\n",
    "\n",
    "    student_rec = SpeechRecord(student_wav_filename, sample['transcript'], name=\"Student\")\n",
    "    student_rec.align_with(teacher_rec)\n",
    "    mean_distance = student_rec.compare_pitch();\n",
    "    print(f\"mean_distance = {mean_distance}\")\n",
    "\n",
    "    update_compare_plot()\n",
    "    \n",
    "w_compare_btn.on_click(run_compare)\n",
    "\n",
    "\n",
    "# Layout\n",
    "\n",
    "items = [w_select, w_load_btn]\n",
    "w_hbox = widgets.HBox(items)\n",
    "display(w_hbox)\n",
    "\n",
    "display(w_sentence)\n",
    "\n",
    "display(widgets.HBox([\n",
    "    widgets.VBox([widgets.Label(value=\"Teacher's recording:\"), w_audio]),\n",
    "    widgets.VBox([widgets.Label(value=\"Your recording:\"), w_recorder]),\n",
    "    w_compare_btn\n",
    "]))\n",
    "\n",
    "display(fig_cmp)\n",
    "display(fig_teacher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6755e932-735a-4dc8-b21f-cfbe34e2de15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
